###ç”¨langchainæž„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äºº

#å®‰è£…langchain:conda install langchain -c conda-forge

# ç¡®ä¿è®¾ç½®çŽ¯å¢ƒå˜é‡è®©LangSmithå¼€å§‹è®°å½•è·Ÿè¸ª
# export LANGCHAIN_TRACING_V2="true"
# export LANGCHAIN_API_KEY="..."
# åœ¨jupyternotebookä¸­ä¹Ÿå¯ä»¥ï¼š
import getpass
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()

#### å•ç‹¬ä½¿ç”¨è¯­è¨€æ¨¡åž‹ã€‚ä»¥openaiä¸ºä¾‹ï¼špip install -qU langchain-openai
import getpass
import os
os.environ["OPENAI_API_KEY"] = getpass.getpass()
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-3.5-turbo")
# æˆ‘ä»¬å·²ç»èŽ·å–åˆ°äº†æ¨¡åž‹çš„è¿è¡ŒæŽ¥å£ï¼ŒçŽ°åœ¨æ¥ä½¿ç”¨å®ƒè¯•ä¸€ä¸‹
from langchain_core.messages import HumanMessage
model.invoke([HumanMessage(content="Hi! I'm Bob")])#ä¸ºä»€ä¹ˆä½¿ç”¨HumanMessageå‘¢ï¼Ÿå› ä¸ºå¯èƒ½è¿˜ä¼šæœ‰ä¸€äº›å…¶ä»–ç±»åž‹çš„Messageï¼Œå…ˆä¸è¦åœ¨æ„
#è¿”å›žå€¼å¦‚ä¸‹
#AIMessage(content='Hello Bob! How can I assist you today?', 
          #response_metadata={'token_usage': {'completion_tokens': 10
                                             #'prompt_tokens': 12, 
                                             #'total_tokens': 22}, 
                              #'model_name': 'gpt-4o-mini', 
                              #'system_fingerprint': None, 
                              #'finish_reason': 'stop', 
                              #'logprobs': None}, 
          #id='run-d939617f-0c3b-45e9-a93f-13dafecbd4b5-0', 
          #usage_metadata={'input_tokens': 12, 
                          #'output_tokens': 10, 
                          #'total_tokens': 22})
                          
#### ä½†æ˜¯çŽ°åœ¨æ¨¡åž‹æ˜¯æ²¡æœ‰çŠ¶æ€æ¦‚å¿µçš„ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰è®°å¿†ï¼Œæ¯æ¬¡éƒ½æ˜¯ä¸€æ¬¡æ–°å¯¹è¯
# æ¯”å¦‚ç»§ç»­é—®ä¸€ä¸ªåŽç»­çš„é—®é¢˜
model.invoke([HumanMessage(content="What's my name?")])
# è¿”å›žå€¼å¦‚ä¸‹
#AIMessage(content="I'm sorry, I don't have access to personal information unless you provide it to me. How may I assist you today?", 
          #response_metadata={'token_usage': {'completion_tokens': 26, 
                                             #'prompt_tokens': 12, 
                                             #'total_tokens': 38}, 
                             #'model_name': 'gpt-4o-mini', 
                             #'system_fingerprint': None, 
                             #'finish_reason': 'stop', 
                             #'logprobs': None}, 
          #id='run-47bc8c20-af7b-4fd2-9345-f0e9fdf18ce3-0', 
          #usage_metadata={'input_tokens': 12, 'output_tokens': 26, 'total_tokens': 38})
          
#### ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦å°†æ•´ä¸ªå¯¹è¯åŽ†å²ä¼ é€’ç»™æ¨¡åž‹ï¼Œæ¥å°è¯•ä¸€ä¸‹ï¼Œçœ‹èµ·æ¥æ•ˆæžœè¿˜ä¸é”™
from langchain_core.messages import AIMessage
model.invoke(
    [
        HumanMessage(content="Hi! I'm Bob"),
        AIMessage(content="Hello Bob! How can I assist you today?"),
        HumanMessage(content="What's my name?"),
    ]
)
#AIMessage(content='Your name is Bob. How can I help you, Bob?', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 35, 'total_tokens': 48}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9f90291b-4df9-41dc-9ecf-1ee1081f4490-0', usage_metadata={'input_tokens': 35, 'output_tokens': 13, 'total_tokens': 48})

#### è¿™äº›æ˜¯æ”¯æ’‘èŠå¤©æœºå™¨äººå¯¹è¯çš„åŸºæœ¬æ¦‚å¿µï¼ŒæŽ¥ä¸‹æ¥å¯ä»¥ä½¿ç”¨æ¶ˆæ¯åŽ†å²ç±»æ¥åŒ…è£…æˆ‘ä»¬çš„æ¨¡åž‹ï¼Œ
#ä½¿å…¶å…·æœ‰çŠ¶æ€ï¼Œèƒ½å¤Ÿè·Ÿè¸ªæ¨¡åž‹çš„è¾“å…¥è¾“å‡ºï¼Œå¹¶å­˜å‚¨ä¸‹æ¥ï¼Œæœªæ¥çš„äº¤äº’å°†åŠ è½½è¿™äº›æ¶ˆæ¯ï¼Œå¹¶ä¸”ä¸€å¹¶ä¼ é€’ç»™æ¨¡åž‹é“¾

######################################### æ¶ˆæ¯åŽ†å² #########################################
#### é¦–å…ˆè¦å®‰è£…langchain-communityæ¨¡å—ï¼špip install langchain_community
# ä»Ž langchain_core.chat_history æ¨¡å—ä¸­å¯¼å…¥åŸºç¡€èŠå¤©è®°å½•ç±»å’ŒåŸºäºŽå†…å­˜çš„èŠå¤©è®°å½•å®žçŽ°
from langchain_core.chat_history import (
    BaseChatMessageHistory,
    InMemoryChatMessageHistory,
)# ä»Ž langchain_core.runnables.history æ¨¡å—ä¸­å¯¼å…¥æ”¯æŒèŠå¤©è®°å½•åŠŸèƒ½çš„ Runnable ç±»
from langchain_core.runnables.history import RunnableWithMessageHistory
store = {}# å®šä¹‰ä¸€ä¸ªå…¨å±€å­—å…¸ï¼Œç”¨äºŽå­˜å‚¨ä¸åŒä¼šè¯(session)çš„èŠå¤©è®°å½•
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    """
    æ ¹æ®ä¼šè¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ session_id èŽ·å–å¯¹åº”çš„èŠå¤©è®°å½•ã€‚
    å¦‚æžœä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„ InMemoryChatMessageHistory å®žä¾‹ï¼Œå¹¶å­˜å…¥å…¨å±€ store å­—å…¸ä¸­ã€‚
    è¿”å›žå€¼ä¸º BaseChatMessageHistory ç±»åž‹çš„å®žä¾‹ã€‚
    """
    if session_id not in store:# å¦‚æžœå…¨å±€å­—å…¸ä¸­ä¸å­˜åœ¨è¯¥ session_id çš„èŠå¤©è®°å½•ï¼Œåˆ™åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„å†…å­˜èŠå¤©è®°å½•
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]# è¿”å›žå¯¹åº” session_id çš„èŠå¤©è®°å½•å®žä¾‹
# æ­¤å¤„å°†æ¨¡åž‹åŒ…è£…æˆæ”¯æŒèŠå¤©è®°å½•åŠŸèƒ½çš„ Runnable å¯¹è±¡ï¼Œä»¥åŽæˆ‘ä»¬å°±ç”¨è¿™ä¸ªå¯¹è±¡æ¥è¿›è¡Œæ“ä½œäº†
# get_session_history ç”¨äºŽåŠ¨æ€èŽ·å–æˆ–åˆ›å»ºä¸Žæ¯ä¸ªä¼šè¯å…³è”çš„èŠå¤©è®°å½•
with_message_history = RunnableWithMessageHistory(model, get_session_history)
# æˆ‘ä»¬çŽ°åœ¨éœ€è¦åˆ›å»ºä¸€ä¸ªconfigï¼Œæ¯æ¬¡å°†å®ƒä¼ é€’ç»™RunnableWithMessageHistoryè¿™ä¸ªåŒ…è£…æ¨¡åž‹
config = {"configurable": {"session_id": "abc2"}}#ä»£è¡¨æˆ‘ä»¬æƒ³åœ¨abc2è¿™ä¸ªä¼šè¯ä¸‹è¿›è¡Œè¾“å…¥
response = with_message_history.invoke(#ç”¨åŒ…è£…å¥½çš„æ¨¡åž‹è¿›è¡Œè°ƒç”¨
    [HumanMessage(content="Hi! I'm Bob")],#ä¸ºä»€ä¹ˆä½¿ç”¨HumanMessageå‘¢ï¼Ÿ
    config=config,
)
response.content#è¾“å‡º'Hi Bob! How can I assist you today?'
response = with_message_history.invoke(#å†è°ƒç”¨ä¸€æ¬¡ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½è®°ä½æˆ‘ä»¬ä¹‹å‰è¯´çš„
    [HumanMessage(content="What's my name?")],
    config=config,
)
response.content#è¾“å‡º'Your name is Bob. How can I help you today, Bob?'

#### éžå¸¸å¥½ï¼ŒçŽ°åœ¨æˆ‘ä»¬çš„åŒ…è£…æ¨¡åž‹å¯ä»¥è®°ä½æˆ‘ä»¬ä¹‹å‰çš„èŠå¤©è®°å½•äº†ï¼Œå¦‚æžœæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„configè®¾ç½®ä¸åŒçš„ä¼šè¯ï¼Œå°±å¯ä»¥å¼€å¯æ–°çš„å¯¹è¯äº†
config = {"configurable": {"session_id": "abc3"}}
response = with_message_history.invoke(
    [HumanMessage(content="What's my name?")],
    config=config,
)
response.content#è¾“å‡º"I'm sorry, I cannot determine your name as I am an AI assistant and do not have access to that information."
#ä½†æ˜¯å¯ä»¥ç»§ç»­ä¹‹å‰çš„ä¼šè¯
config = {"configurable": {"session_id": "abc2"}}
response = with_message_history.invoke(
    [HumanMessage(content="What's my name?")],
    config=config,
)
response.content#è¾“å‡º'Your name is Bob. How can I assist you today, Bob?'

######################################### æç¤ºè¯æ¨¡æ¿ #########################################
#### æç¤ºè¯æ¨¡æ¿å¸®åŠ©æˆ‘ä»¬æŠŠåŽŸå§‹ç”¨æˆ·è¾“å…¥ä¿¡æ¯è½¬æ¢æˆå¤§è¯­è¨€æ¨¡åž‹æ›´å¥½å¤„ç†çš„æ ¼å¼ï¼Œ
# æœ¬æ¥åŽŸå§‹ç”¨æˆ·è¾“å…¥çš„åªæ˜¯ä¸€ä¸ªæ¶ˆæ¯ï¼ŒçŽ°åœ¨æˆ‘ä»¬æ¥è®©è¿™ä¸ªæ¶ˆæ¯å˜çš„æ›´åŠ å¤æ‚ä¸€ç‚¹ï¼Œ
# é¦–å…ˆæ·»åŠ ä¸€ä¸ªå¸¦æœ‰ä¸€äº›è‡ªå®šä¹‰æŒ‡ä»¤çš„ç³»ç»Ÿæ¶ˆæ¯ï¼ˆä½†ä»ç„¶å°†æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼‰
# ç„¶åŽæ·»åŠ é™¤äº†æ¶ˆæ¯ä¹‹å¤–çš„æ›´å¤šè¾“å…¥

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# ä½¿ç”¨ from_messages æ–¹æ³•æ ¹æ®æ¶ˆæ¯åˆ—è¡¨åˆ›å»ºä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ (ChatPromptTemplate)
# è¯¥æ¨¡æ¿åŒ…å«ä¸¤éƒ¨åˆ†ï¼š
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",#ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ï¼Œç”¨äºŽè®¾ç½®åŠ©æ‰‹çš„è§’è‰²å’Œè¡Œä¸ºå‡†åˆ™
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        #ä¸€ä¸ªæ¶ˆæ¯å ä½ç¬¦ (MessagesPlaceholder)ï¼Œä¼šæŠŠ"messages"å¯¹åº”çš„è¾“å…¥å¯¹è±¡ï¼ˆæ¯”å¦‚HumanMessageï¼‰è§£æžæ‹¼æŽ¥åˆ°prompté‡Œ
        MessagesPlaceholder(variable_name="messages"),
    ]
)
# æ¨¡æ¿åšå¥½äº†ä¹‹åŽï¼Œæˆ‘ä»¬æŠŠè¿™ä¸ªæ¨¡æ¿æ”¾å…¥é“¾çš„æœ€å‰ç«¯
chain = prompt | model# ä½¿ç”¨ç®¡é“è¿ç®—ç¬¦ (|) å°†æç¤ºæ¨¡æ¿ (prompt) ä¸Žæ¨¡åž‹ (model) ç»„åˆï¼Œå½¢æˆä¸€ä¸ªå¤„ç†é“¾ (chain)

#### å¥½äº†ï¼Œæˆ‘ä»¬çŽ°åœ¨æœ‰äº†è¿™ä¸ªå¸¦æœ‰æç¤ºè¯æ¨¡æ¿çš„æ¨¡åž‹é“¾ï¼Œæ¥è°ƒç”¨ä¸€ä¸‹
# è¯·æ³¨æ„ï¼Œæˆ‘ä»¬çŽ°åœ¨çš„è¾“å…¥æ˜¯ä¸€ä¸ªåŒ…å«messagesé”®çš„å­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ¶ˆæ¯åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ç›´æŽ¥ä¼ é€’æ¶ˆæ¯åˆ—è¡¨
# å› ä¸ºè¿™ä¸ªè¾“å…¥æ˜¯ç»™æç¤ºè¯æ¨¡æ¿ç”¨çš„ï¼Œå› ä¸ºè¿™ä¸ªè¾“å…¥æ˜¯ç»™æç¤ºè¯æ¨¡æ¿ç”¨çš„ï¼Œæç¤ºè¯æ¨¡æ¿ä¼šæŠŠè¿™ä¸ªå­—å…¸æ‹¼æŽ¥åˆ°è¾“å…¥ä¸­ç»™æ¨¡åž‹
response = chain.invoke({"messages": [HumanMessage(content="hi! I'm bob")]})
response.content# è¾“å‡º'Hello Bob! How can I assist you today?'
# æˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠè¿™ä¸ªæ¨¡åž‹é“¾ä¹ŸåšæˆåŒ…è£…æ¨¡åž‹ï¼Œåƒä¹‹å‰ä¸€æ ·å®žçŽ°èŠå¤©è®°å½•çš„åŠŸèƒ½
with_message_history = RunnableWithMessageHistory(chain, get_session_history)
config = {"configurable": {"session_id": "abc5"}}#é…ç½®ä¸€ä¸‹ä¼šè¯id
# HumanMessage(content="Hi! I'm Jim")ç»è¿‡promptå°†ä¼šå’Œæç¤ºè¯æ¨¡æ¿ä¸­çš„å…¶ä»–æç¤ºè¯æ‹¼æŽ¥
# ä½†æ˜¯è¿™é‡Œä¸ºä»€ä¹ˆä¸éœ€è¦ä½¿ç”¨å­—å…¸äº†å‘¢ï¼Ÿä¸ä½¿ç”¨å­—å…¸ï¼Œpromptæ€Žä¹ˆçŸ¥é“è¿™ä¸ªHumanMessageå¯¹è±¡éœ€è¦æ”¾å…¥å“ªä¸ªæ¶ˆæ¯å ä½ç¬¦é‡Œ
response = with_message_history.invoke(
    [HumanMessage(content="Hi! I'm Jim")],
    config=config,
)
response.content#è¾“å‡º'Hello, Jim! How can I assist you today?'
response = with_message_history.invoke(
    [HumanMessage(content="What's my name?")],
    config=config,
)
response.content#è¾“å‡º'Your name is Jim.'

#### æˆ‘ä»¬å·²ç»å­¦ä¼šäº†åŸºæœ¬çš„æç¤ºè¯æ¨¡æ¿çš„ä½¿ç”¨ï¼ŒçŽ°åœ¨è®©æˆ‘ä»¬çš„æç¤ºè¯å˜å¾—æ›´åŠ å¤æ‚ä¸€ç‚¹
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability in {language}.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)
chain = prompt | model
# è¯·æ³¨æ„æˆ‘ä»¬åœ¨æç¤ºä¸­æ·»åŠ äº†ä¸€ä¸ªè¾“å…¥ï¼šlanguageï¼Œçœ‹çœ‹è¿™æ ·æˆ‘ä»¬åº”è¯¥æ€Žä¹ˆè°ƒç”¨é“¾å¹¶ä¼ å…¥æˆ‘ä»¬çš„è¾“å…¥
response = chain.invoke(
    {"messages": [HumanMessage(content="hi! I'm bob")], "language": "Spanish"}
)
response.content#è¾“å‡º'Â¡Hola, Bob! Â¿En quÃ© puedo ayudarte hoy?'
#å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„è¾“å…¥æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyï¼šmessagesçš„valueæ˜¯ä¸€ä¸ªHumanMessageå¯¹è±¡ï¼Œkeyï¼šlanguageçš„valueæ˜¯"Spanish"
#promptæ¨¡å—å°†ä¼šæŠŠè¿™ä¸ªå­—å…¸çš„valueæ›¿æ¢æŽ‰å¯¹åº”çš„å ä½ç¬¦

####çŽ°åœ¨æˆ‘ä»¬æŠŠè¿™ä¸ªæ›´åŠ å¤æ‚çš„é“¾å°è£…åœ¨ä¸€ä¸ªæ¶ˆæ¯åŽ†å²ç±»ä¸­ï¼Œä¹Ÿå°±æ˜¯ä¹‹å‰è¯´çš„åŒ…è£…æ¨¡åž‹
# è¿™æ¬¡ï¼Œç”±äºŽè¾“å…¥ä¸­æœ‰å¤šä¸ªé”®ï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šæ­£ç¡®çš„é”®æ¥ä¿å­˜èŠå¤©åŽ†å²ï¼Œå…¶ä»–é”®çš„å†…å®¹æ˜¯ä¸éœ€è¦ä¿å­˜åˆ°èŠå¤©è®°å½•çš„
with_message_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    #input_messages_key æŒ‡å®šä»Žè¾“å…¥å­—å…¸ä¸­å“ªä¸ªé”®æå–èŠå¤©æ¶ˆæ¯ï¼ˆæ­¤å¤„ä¸º "messages"ï¼‰
    #ä¸ºä»€ä¹ˆéœ€è¦æŒ‡å®šå‘¢ï¼Œå› ä¸ºå…¶ä»–çš„é”®ï¼Œä¹Ÿå°±æ˜¯languageçš„å†…å®¹æ˜¯ä¸éœ€è¦ä¿å­˜åˆ°èŠå¤©è®°å½•é‡Œçš„
    input_messages_key="messages",
)
config = {"configurable": {"session_id": "abc11"}}
response = with_message_history.invoke(#ä¼ å…¥ä¸€ä¸ªåŒ…å«å¤šä¸ªé”®çš„è¾“å…¥å­—å…¸ï¼š
    # - "messages" é”®ï¼šåŒ…å«ä¸€ä¸ª HumanMessage å¯¹è±¡åˆ—è¡¨ï¼Œä»£è¡¨ç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆè¿™é‡Œæ˜¯ "hi! I'm todd"ï¼‰
    # - "language" é”®ï¼šæŒ‡å®šå¸Œæœ›ç”Ÿæˆçš„å“åº”è¯­è¨€ï¼ˆè¿™é‡Œä¸ºè¥¿ç­ç‰™è¯­ï¼‰
    {"messages": [HumanMessage(content="hi! I'm todd")], "language": "Spanish"},
    config=config,
)
#å¯¹æ¯”ä¸€ä¸‹ä¹‹å‰çš„invokeä¸éœ€è¦æŒ‡å®šé”®ï¼Œå› ä¸ºpromptåªæœ‰ä¸€ä¸ªå ä½ç¬¦
#response = with_message_history.invoke(
#    [HumanMessage(content="Hi! I'm Jim")],
#    config=config,
#)
response.content#è¾“å‡º'Â¡Hola Todd! Â¿En quÃ© puedo ayudarte hoy?'
response = with_message_history.invoke(
    {"messages": [HumanMessage(content="whats my name?")], "language": "Spanish"},
    config=config,
)
response.content#è¾“å‡º'Tu nombre es Todd.'

######################################### ç®¡ç†å¯¹è¯åŽ†å² #########################################
####å¯¹äºŽèŠå¤©æœºå™¨äººè€Œè¨€ï¼Œéœ€è¦ç®¡ç†å¯¹è¯åŽ†å²ï¼Œå¦‚æžœä¸ç®¡ç†ï¼Œæ¶ˆæ¯åˆ—è¡¨å°†ä¼šæ— é™å¢žé•¿ï¼Œæº¢å‡ºä¸Šä¸‹æ–‡çª—å£ï¼Œ
# å› æ­¤éœ€è¦å¯¹ä¼ å…¥æ¶ˆæ¯çš„å¤§å°è¿›è¡Œé™åˆ¶ï¼Œ
# éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œéœ€è¦åœ¨ æç¤ºæ¨¡æ¿ä¹‹å‰ ä½†æ˜¯ æ¶ˆæ¯åŽ†å²åŠ è½½ä¹‹åŽ çš„æ¶ˆæ¯ä¸Šæ‰§è¡Œæ­¤æ“ä½œ
# æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨æç¤ºå‰æ·»åŠ ä¸€ä¸ªç®€å•çš„æ­¥éª¤ï¼Œé€‚å½“åœ°ä¿®æ”¹ messages é”®ï¼Œç„¶åŽå°†è¯¥æ–°é“¾å°è£…åœ¨æ¶ˆæ¯åŽ†å²ç±»ä¸­æ¥å®žçŽ°ã€‚
# LangChain æä¾›äº†ä¸€äº›å†…ç½®çš„åŠ©æ‰‹æ¥ ç®¡ç†æ¶ˆæ¯åˆ—è¡¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ trim_messages åŠ©æ‰‹æ¥å‡å°‘æˆ‘ä»¬å‘é€ç»™æ¨¡åž‹çš„æ¶ˆæ¯æ•°é‡ã€‚
#ä¿®å‰ªå™¨å…è®¸æˆ‘ä»¬æŒ‡å®šå¸Œæœ›ä¿ç•™çš„ä»¤ç‰Œæ•°é‡ï¼Œä»¥åŠå…¶ä»–å‚æ•°ï¼Œä¾‹å¦‚æ˜¯å¦å¸Œæœ›å§‹ç»ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ä»¥åŠæ˜¯å¦å…è®¸éƒ¨åˆ†æ¶ˆæ¯ï¼š
from langchain_core.messages import SystemMessage, trim_messages
# åˆ›å»ºä¸€ä¸ªæ¶ˆæ¯ä¿®å‰ªå™¨ (trimmer) å¯¹è±¡ï¼Œç”¨äºŽæŽ§åˆ¶æ¶ˆæ¯åˆ—è¡¨çš„æœ€å¤§ token æ•°é‡
trimmer = trim_messages(
    max_tokens=65,# ä¿®å‰ªåŽçš„æ¶ˆæ¯åˆ—è¡¨ä¸­æ€»å…±å…è®¸çš„æœ€å¤§ tokens æ•°é‡ä¸º 65
    strategy="last",# é‡‡ç”¨ä¿ç•™æœ€åŽå‡ æ¡æ¶ˆæ¯çš„ç­–ç•¥è¿›è¡Œä¿®å‰ª
    token_counter=model,# ä½¿ç”¨ model ä½œä¸ºè®¡æ•° token çš„å‡½æ•°æˆ–å¯¹è±¡
    include_system=True,# åŒ…æ‹¬ç³»ç»Ÿæ¶ˆæ¯åœ¨å†…è¿›è¡Œ token è®¡ç®—
    allow_partial=False,# ä¸å…è®¸éƒ¨åˆ†æ¶ˆæ¯è¢«ä¿ç•™ï¼Œä¿®å‰ªæ—¶è¦ä¹ˆå®Œå…¨ä¿ç•™ï¼Œè¦ä¹ˆåˆ é™¤
    start_on="human",# ä»Žç¬¬ä¸€æ¡äººç±»æ¶ˆæ¯å¼€å§‹è€ƒè™‘ä¿®å‰ªé€»è¾‘
)
# æž„å»ºä¸€ä¸ªåŒ…å«ä¸åŒè§’è‰²æ¶ˆæ¯çš„å¯¹è¯åŽ†å²åˆ—è¡¨
messages = [
    SystemMessage(content="you're a good assistant"),   # ç³»ç»Ÿæ¶ˆæ¯ï¼Œç”¨äºŽè®¾å®šè§’è‰²æˆ–æŒ‡ä»¤
    HumanMessage(content="hi! I'm bob"),                # äººç±»æ¶ˆæ¯
    AIMessage(content="hi!"),                           # AI æ¶ˆæ¯
    HumanMessage(content="I like vanilla ice cream"),   # äººç±»æ¶ˆæ¯
    AIMessage(content="nice"),                          # AI æ¶ˆæ¯
    HumanMessage(content="whats 2 + 2"),                # äººç±»æ¶ˆæ¯
    AIMessage(content="4"),                             # AI æ¶ˆæ¯
    HumanMessage(content="thanks"),                     # äººç±»æ¶ˆæ¯
    AIMessage(content="no problem!"),                   # AI æ¶ˆæ¯
    HumanMessage(content="having fun?"),                # äººç±»æ¶ˆæ¯
    AIMessage(content="yes!"),                          # AI æ¶ˆæ¯
]
# è°ƒç”¨ä¿®å‰ªå™¨ï¼Œå°†æ¶ˆæ¯åˆ—è¡¨ä¿®å‰ªä¸ºç¬¦åˆ max_tokens é™åˆ¶çš„å­åˆ—è¡¨
# è¿”å›žçš„ç»“æžœå°†åªåŒ…å«æ€» tokens æ•°ä¸è¶…è¿‡ 65 çš„æ¶ˆæ¯
trimmer.invoke(messages)
#è¾“å‡º
#[SystemMessage(content="you're a good assistant"),
# HumanMessage(content='whats 2 + 2'),
# AIMessage(content='4'),
# HumanMessage(content='thanks'),
# AIMessage(content='no problem!'),
# HumanMessage(content='having fun?'),
# AIMessage(content='yes!')]

#### è¿™ä¸ªä¿®å‰ªå™¨æˆ‘ä»¬å·²ç»åˆ›å»ºå¥½äº†ï¼Œæƒ³è¦åœ¨æˆ‘ä»¬çš„é“¾ä¸­ä½¿ç”¨å®ƒï¼Œåªéœ€è¦åœ¨å°†messageè¾“å…¥ä¼ é€’ç»™promptä¹‹å‰è¿è¡Œä¿®å‰ªå™¨å³å¯
from operator import itemgetter

from langchain_core.runnables import RunnablePassthrough

chain = (
    # RunnablePassthrough.assign éƒ¨åˆ†ï¼š
        # ä½¿ç”¨ itemgetter("messages") ä»Žè¾“å…¥å­—å…¸ä¸­æå– "messages" é”®å¯¹åº”çš„å€¼
        # å°†æå–åˆ°çš„æ¶ˆæ¯åˆ—è¡¨é€šè¿‡ç®¡é“æ“ä½œç¬¦ä¼ ç»™ trimmer è¿›è¡Œæ¶ˆæ¯ä¿®å‰ªå¤„ç†
        # ç»“æžœä¼šè¢«åˆ†é…ç»™åŽç»­çŽ¯èŠ‚ä¸­åä¸º "messages" çš„è¾“å…¥é”®
    RunnablePassthrough.assign(messages=itemgetter("messages") | trimmer)
    | prompt
    | model
)

response = chain.invoke(
    {
        #"messages": åŽŸå§‹æ¶ˆæ¯åˆ—è¡¨ messages åŠ ä¸Šä¸€ä¸ªé¢å¤–çš„ HumanMessageï¼Œ
        #å†…å®¹ä¸º "what's my name?"ï¼Œä»¥æ‰©å±•å¯¹è¯åŽ†å²
        "messages": messages + [HumanMessage(content="what's my name?")],
        "language": "English",
    }
)
response.content# è¾“å‡ºï¼š"I'm sorry, but I don't have access to your personal information. How can I assist you today?"
# ä½†æ˜¯æˆ‘ä»¬è¯¢é—®æœ€è¿‘å‡ æ¡æ¶ˆæ¯ä¸­çš„ä¿¡æ¯ï¼Œå®ƒä¼šè®°ä½
response = chain.invoke(
    {
        "messages": messages + [HumanMessage(content="what math problem did i ask")],
        "language": "English",
    }
)
response.content#è¾“å‡º 'You asked "what\'s 2 + 2?"'

#### çŽ°åœ¨è®©æˆ‘ä»¬æŠŠå®ƒåŒ…è£…åœ¨ æ¶ˆæ¯åŽ†å² ä¸­
with_message_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="messages",
)
config = {"configurable": {"session_id": "abc20"}}
# æ¥è°ƒç”¨ä¸€ä¸‹ï¼
response = with_message_history.invoke(
    {
        "messages": messages + [HumanMessage(content="whats my name?")],
        "language": "English",
    },
    config=config,
)
response.content#è¾“å‡º "I'm sorry, I don't have access to that information. How can I assist you today?"

######################################### æµå¼å¤„ç† #########################################
# çŽ°åœ¨æˆ‘ä»¬æœ‰äº†ï¼Œèƒ½å¤Ÿè®°ä½èŠå¤©è®°å½•ï¼Œå¹¶ä¸”ä¼šè®¾ç½®æœ€å¤§é•¿åº¦è¿›è¡Œè£å‰ªè®°å½•ï¼Œå¹¶ä¸”æœ‰æç¤ºè¯æ¨¡å—çš„èŠå¤©æœºå™¨äººäº†
# ä½†æ˜¯å¯¹äºŽèŠå¤©æœºå™¨äººæ¥è¯´ï¼Œéžå¸¸é‡è¦çš„ä¸€ä¸ªä½“éªŒæ˜¯æµå¼å¤„ç†ï¼Œå®žé™…ä¸Šï¼Œæˆ‘ä»¬åªéœ€è¦è®©æ‰€æœ‰é“¾éƒ½æš´éœ²ä¸€ä¸ª.streamæ–¹æ³•å³å¯
# ä½¿ç”¨æ¶ˆæ¯åŽ†å²çš„é“¾ä¹Ÿä¸ä¾‹å¤–ï¼Œå¯ä»¥ç®€å•çš„ä½¿ç”¨è¯¥æ–¹æ³•èŽ·å–æµå¼å“åº”
config = {"configurable": {"session_id": "abc15"}}
for r in with_message_history.stream(
    {
        "messages": [HumanMessage(content="hi! I'm todd. tell me a joke")],
        "language": "English",
    },
    config=config,
):
    print(r.content, end="|")
    #è¾“å‡ºï¼š|Hi| Todd|!| Sure|,| here|'s| a| joke| for| you|:| Why| couldn|'t| the| bicycle| find| its| way| home|?| Because| it| lost| its| bearings|!| ðŸ˜„||
    
    
    
######################################### å¯¹è¯å¼RAG #########################################
# å¥½äº†ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¼šäº†æž„å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººï¼Œä½†æ˜¯åœ¨è®¸å¤šé—®ç­”åº”ç”¨ä¸­ï¼Œç”¨æˆ·æƒ³è¦è¿›è¡Œåå¤é—®è¯ï¼Œ
# è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦æŸç§å½¢å¼çš„"è®°å¿†"æ¥è®°å½•è¿‡åŽ»çš„é—®é¢˜å’Œç­”æ¡ˆï¼Œå¹¶èƒ½å¤Ÿå°†è¿™äº›ä¿¡æ¯èžå…¥å½“å‰æ€è€ƒçš„é€»è¾‘
# çŽ°åœ¨æˆ‘ä»¬é‡ç‚¹å…³æ³¨ æ·»åŠ ç”¨äºŽæ•´åˆåŽ†å²æ¶ˆæ¯çš„é€»è¾‘
# å°†æœ‰ä¸¤ç§æ–¹æ³•ï¼š
# é“¾æŽ¥ï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬å§‹ç»ˆæ‰§è¡Œæ£€ç´¢æ­¥éª¤
# ä»£ç†ï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬ç»™äºˆllmè‡ªç”±å†³å®šæ˜¯å¦ï¼Œä»¥åŠå¦‚ä½•æ‰§è¡Œæ£€ç´¢æ­¥éª¤ï¼ˆæˆ–å¤šä¸ªæ­¥éª¤ï¼‰
# å¯¹äºŽå¤–éƒ¨çŸ¥è¯†æºï¼Œæˆ‘ä»¬å°†ä½¿ç”¨LilianWengçš„åŒä¸€ç¯‡LLM Powered Autonomous Agentsåšå®¢æ–‡ç« ï¼Œæ¥è‡ªRAGæ•™ç¨‹

####è®¾ç½®
# åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨openaiåµŒå…¥å’Œchromaå‘é‡åµŒå…¥ï¼Œä½†æ˜¯è¿™é‡Œå±•ç¤ºçš„æ‰€æœ‰å†…å®¹ï¼Œé€‚ç”¨äºŽä»»ä½•åµŒå…¥å’Œå‘é‡å­˜å‚¨æˆ–æ£€ç´¢å™¨
# ä½¿ç”¨ä»¥ä¸‹è½¯ä»¶åŒ…
# ä½¿ç”¨è¯¥å‘½ä»¤å¯ä»¥éšè—æ­£å¸¸çš„è¾“å‡ºä¿¡æ¯ï¼Œä½†å¦‚æžœä»£ç å‡ºé”™ï¼Œé”™è¯¯ä¿¡æ¯ä»ä¼šæ˜¾ç¤ºåœ¨ Notebook ä¸­ã€‚
%%capture --no-stderr
%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma beautifulsoup4
# æˆ‘ä»¬éœ€è¦è®¾ç½®çŽ¯å¢ƒå˜é‡ OPENAI_API_KEYï¼Œå¯ä»¥ç›´æŽ¥è®¾ç½®æˆ–ä»Ž .env æ–‡ä»¶ä¸­åŠ è½½
import getpass
import os
if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass.getpass()
# import dotenv
# dotenv.load_dotenv()
# å¦‚æžœæ‚¨ç¡®å®žæƒ³ä½¿ç”¨ LangSmithæ£€æŸ¥æ‚¨çš„é“¾æˆ–ä»£ç†å†…éƒ¨ç©¶ç«Ÿå‘ç”Ÿäº†ï¼Œè¯·ç¡®ä¿è®¾ç½®æ‚¨çš„çŽ¯å¢ƒå˜é‡ä»¥å¼€å§‹è®°å½•è·Ÿè¸ªï¼š
os.environ["LANGCHAIN_TRACING_V2"] = "true"
if not os.environ.get("LANGCHAIN_API_KEY"):
    os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
    
####é“¾
#å…ˆæ¥å›žé¡¾ä»¥ä¸‹æˆ‘ä»¬ä¹‹å‰åšçš„èŠå¤©æœºå™¨äºº
pip install -qU langchain-openai#è®°å¾—å®‰è£…ä»¥ä¸‹

import getpass
import os
os.environ["OPENAI_API_KEY"] = getpass.getpass()
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o-mini")#åˆ›å»ºllmæ“ä½œå¯¹è±¡

import bs4
from langchain import hub
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
# 1.åŠ è½½ã€åˆ†å—å¹¶ç´¢å¼•åšå®¢çš„å†…å®¹ä»¥åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨ã€‚
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),# ä½¿ç”¨ WebBaseLoader ä»ŽæŒ‡å®šçš„ URL åŠ è½½ç½‘é¡µå†…å®¹ã€‚
    # bs_kwargs å‚æ•°ç”¨äºŽä¼ é€’ BeautifulSoup çš„å‚æ•°ï¼Œè¿™é‡Œé€šè¿‡ SoupStrainer æŒ‡å®šåªè§£æžåŒ…å«ç‰¹å®š class çš„ HTML å…ƒç´ ï¼Œ
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")# è¿™äº›å…ƒç´ åŒ…æ‹¬ "post-content"ã€"post-title" å’Œ "post-header"ã€‚
        )
    ),
)

docs = loader.load()# è°ƒç”¨ load æ–¹æ³•åŠ è½½ç½‘é¡µå†…å®¹ï¼Œè¿”å›žæ–‡æ¡£åˆ—è¡¨ã€‚åªåŠ è½½åšå®¢ä¸­çš„æ­£æ–‡å†…å®¹ã€æ ‡é¢˜ä»¥åŠé¡µçœ‰éƒ¨åˆ†ï¼Œè€Œå¿½ç•¥å…¶å®ƒæ— å…³å†…å®¹ã€‚

# åˆ›å»ºä¸€ä¸ª RecursiveCharacterTextSplitterï¼Œç”¨äºŽå°†æ–‡æ¡£åˆ†å—ã€‚
#   chunk_size=1000 è¡¨ç¤ºæ¯ä¸ªå—çš„æœ€å¤§å­—ç¬¦æ•°ï¼Œ
#   chunk_overlap=200 è¡¨ç¤ºç›¸é‚»å—ä¹‹é—´æœ‰ 200 ä¸ªå­—ç¬¦çš„é‡å ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¿žç»­æ€§ã€‚
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

# è¿™ä¸€æ­¥ä¼šéåŽ† docs ä¸­çš„æ¯ä¸ªæ–‡æ¡£ï¼Œæ ¹æ®è®¾å®šçš„å­—ç¬¦æ•°é™åˆ¶å°†å…¶æ‹†åˆ†æˆå¤šä¸ªè¾ƒå°çš„æ–‡æœ¬å—ï¼Œ
# æ¯ä¸ªå—éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ–‡æ¡£ç‰‡æ®µï¼Œå­˜å‚¨åœ¨ splits åˆ—è¡¨ä¸­ã€‚
splits = text_splitter.split_documents(docs)#è¿›è¡Œåˆ†å—ï¼Œç”Ÿæˆåˆ†å—åŽçš„æ–‡æ¡£åˆ—è¡¨ã€‚

# ä½¿ç”¨ Chroma.from_documents æ–¹æ³•å°†åˆ†å—åŽçš„æ–‡æ¡£åˆ—è¡¨è½¬æ¢ä¸ºå‘é‡å­˜å‚¨ï¼ˆvectorstoreï¼‰
# ä½¿ç”¨ OpenAIEmbeddings() å¯¹æ¯ä¸ªæ–‡æœ¬å—ç”Ÿæˆå‘é‡åµŒå…¥ï¼Œå®žçŽ°æ–‡æœ¬çš„æ•°å€¼åŒ–è¡¨ç¤ºï¼Œ
 # ä»¥ä¾¿åŽç»­é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ¥å¿«é€Ÿæ£€ç´¢ç›¸å…³å†…å®¹ã€‚
## æ³¨æ„ï¼šæ¯ä¸ªæ–‡æ¡£å—ï¼ˆchunkï¼‰ä¼šè¢«æ•´ä½“è½¬æ¢æˆä¸€ä¸ªå‘é‡ï¼Œè€Œä¸æ˜¯å¯¹æ–‡æ¡£ä¸­çš„æ¯ä¸ª token å•ç‹¬è¿›è¡ŒåµŒå…¥ã€‚
## ä¹Ÿå°±æ˜¯è¯´ï¼Œæ•´ä¸ªæ–‡æœ¬å—ä½œä¸ºä¸€ä¸ªè¾“å…¥è¢«ä¼ é€’ç»™ OpenAIEmbeddings æ¨¡åž‹ï¼Œç„¶åŽç”Ÿæˆä¸€ä¸ªå‘é‡æ¥ä»£è¡¨è¿™ä¸ªå—çš„è¯­ä¹‰ä¿¡æ¯ã€‚
vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())
# å°†å‘é‡å­˜å‚¨è½¬æ¢ä¸ºæ£€ç´¢å™¨å¯¹è±¡ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ä»Žå­˜å‚¨çš„å‘é‡ä¸­æ‰¾å‡ºæœ€ç›¸å…³çš„æ–‡æ¡£å—ã€‚
#   è¾“å…¥ï¼šé€šå¸¸æ˜¯ä¸€ä¸ªæŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ç”¨æˆ·çš„é—®é¢˜æˆ–æœç´¢å…³é”®å­—ï¼‰ã€‚åœ¨å†…éƒ¨ï¼Œretriever ä¼šå¯¹è¿™ä¸ªæŸ¥è¯¢è¿›è¡Œå‘é‡åŒ–ï¼Œç„¶åŽä¸Žå‘é‡å­˜å‚¨ä¸­çš„æ‰€æœ‰åµŒå…¥å‘é‡è¿›è¡Œç›¸ä¼¼æ€§æ¯”è¾ƒã€‚
#   è¾“å‡ºï¼šä¸€ä¸ªæ–‡æ¡£å¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£å¯¹è±¡é€šå¸¸åŒ…å«æ–‡æœ¬å†…å®¹å’Œå¯èƒ½çš„å…ƒæ•°æ®ã€‚è¿™äº›æ–‡æ¡£å—æŒ‰ç…§ä¸ŽæŸ¥è¯¢çš„ç›¸å…³æ€§æŽ’åºï¼Œæœ€ç›¸å…³çš„æŽ’åœ¨æœ€å‰é¢ã€‚
retriever = vectorstore.as_retriever()

# 2. å°†æ£€ç´¢å™¨æ•´åˆåˆ°é—®ç­”é“¾ä¸­ã€‚
#       å®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆsystem_promptï¼‰ï¼Œé‡Œé¢æœ‰ä¸Šä¸‹æ–‡å ä½ç¬¦contextï¼š
#       - æŒ‡æ˜ŽåŠ©æ‰‹è§’è‰²ä¸ºé—®ç­”åŠ©æ‰‹ã€‚
#       - æŒ‡ç¤ºä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼ˆ{context}ï¼‰æ¥å›žç­”é—®é¢˜ã€‚
#       - è‹¥ä¸æ¸…æ¥šç­”æ¡ˆï¼Œåˆ™ç›´æŽ¥è¯´æ˜Žä¸çŸ¥é“ã€‚
#       - é™åˆ¶å›žç­”æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ï¼Œå¹¶ä¿æŒç®€æ´ã€‚
system_prompt = (
    "ä½ æ˜¯ä¸€ä¸ªé—®ç­”ä»»åŠ¡åŠ©æ‰‹"
    "ä½¿ç”¨ä»¥ä¸‹æ£€ç´¢çš„æ–‡æ¡£è¿›è¡Œå›žç­”é—®é¢˜"
    "å¦‚æžœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“"
    "é™åˆ¶å›žç­”æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ï¼Œå¹¶ä¿æŒç®€æ´ã€‚"
    "\n\n"
    "{context}"#æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å ä½ç¬¦
)

# ä½¿ç”¨ ChatPromptTemplate.from_messages æ–¹æ³•åˆ›å»ºå¯¹è¯æç¤ºæ¨¡æ¿ï¼ŒçŽ°åœ¨è¿™ä¸ªæ¨¡æ¿ä¸­è¿˜å·®contextæ²¡æœ‰å¡«å…¥
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)

# åˆ›å»ºä¸€ä¸ªæ–‡æ¡£é—®ç­”é“¾ï¼Œinput -(prompt)-> å¸¦æœ‰contextå ä½ç¬¦çš„newinput -(llm)-> output
# create_stuff_documents_chain æ–‡æ¡£å¡«å……é“¾åˆ›å»ºå‡½æ•°
# è¿™é‡Œæ¯”è¾ƒå¥‡æ€ªçš„äº‹æƒ…æ˜¯ä¸ºä»€ä¹ˆllmå†™åœ¨propmtå‰é¢äº†ï¼ŒçœŸå®žçš„å¤„ç†æµç¨‹æ˜¯å…ˆpropmtåŽllm
question_answer_chain = create_stuff_documents_chain(llm, prompt)

# åˆ›å»ºä¸€ä¸ªæ£€ç´¢é—®ç­”é“¾ï¼Œå°†æ£€ç´¢å™¨ï¼ˆretrieverï¼‰ä¸Žé—®ç­”é“¾æ•´åˆåœ¨ä¸€èµ·ï¼Œ
# input -(retriever)-> context+input -(prompt)-> å¸¦æœ‰contextçš„newInput -(llm)-> output
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

#### å¥½äº†ï¼Œæœ€ç»ˆçš„rag_chainæˆ‘ä»¬çŸ¥é“äº†å®ƒçš„æµç¨‹æ˜¯input -(retriever)-> context+input -(prompt)-> å¸¦æœ‰contextçš„newInput -(llm)-> output

response = rag_chain.invoke({"input": "ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£ï¼Ÿ?"})
response["answer"]
#è¾“å‡º  "ä»»åŠ¡åˆ†è§£æ˜¯æŒ‡å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†æˆæ›´å°ã€æ›´ç®€å•çš„æ­¥éª¤ï¼Œä»Žè€Œä½¿ä»»åŠ¡æ›´æ˜“äºŽä»£ç†æˆ–æ¨¡åž‹ç®¡ç†ã€‚
#       è¿™ä¸ªè¿‡ç¨‹æœ‰åŠ©äºŽå¼•å¯¼ä»£ç†å®Œæˆå®žçŽ°æ€»ä½“ä»»åŠ¡æ‰€éœ€çš„å„ä¸ªå­ç›®æ ‡ã€‚å¯ä»¥ä½¿ç”¨è¯¸å¦‚é“¾å¼æ€ç»´ï¼ˆChain of Thoughtï¼‰å’Œ
#       æ ‘çŠ¶æ€ç»´ï¼ˆTree of Thoughtsï¼‰ç­‰ä¸åŒæŠ€æœ¯ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºé€æ­¥æ‰§è¡Œçš„æµç¨‹ï¼Œ
#       ä»Žè€Œæå‡æ¨¡åž‹çš„æ€§èƒ½ï¼Œå¹¶åŠ æ·±å¯¹æ¨¡åž‹æ€è€ƒè¿‡ç¨‹çš„ç†è§£ã€‚"

####æ·»åŠ èŠå¤©åŽ†å²
# æˆ‘ä»¬çŽ°åœ¨æž„å»ºçš„è¿™ä¸ªé“¾å¯ä»¥ä½¿ç”¨è¾“å…¥æ¥æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œä½†æ˜¯åœ¨çŽ°å®žä¸­ï¼Œç”¨æˆ·çš„æ„å›¾å¯èƒ½éœ€è¦å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡æ‰èƒ½ç†è§£
# æ¯”å¦‚ï¼šäººç±»: "ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£ï¼Ÿ"
#       AI: "ä»»åŠ¡åˆ†è§£æ¶‰åŠå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°ã€æ›´ç®€å•çš„æ­¥éª¤ï¼Œä»¥ä¾¿ä½¿ä»£ç†æˆ–æ¨¡åž‹æ›´æ˜“äºŽç®¡ç†ã€‚"
#       äººç±»: "å®ƒå¸¸è§çš„åšæ³•æœ‰å“ªäº›ï¼Ÿ"
# ä¸ºäº†å›žç­”"å®ƒå¸¸è§çš„åšæ³•æœ‰å“ªäº›ï¼Ÿ"è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡åž‹ç†è§£å®ƒæŒ‡çš„æ˜¯"ä»»åŠ¡åˆ†è§£"
# è¿™ä¸ªé—®é¢˜è™½ç„¶å¤§æ¨¡åž‹æœ¬èº«æ˜¯å¯ä»¥ç†è§£ä¸€ç‚¹ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯å¸Œæœ›å¯ä»¥åœ¨æˆ‘ä»¬è¿™é‡Œè¿›è¡Œä¸€äº›ä¼˜åŒ–
# ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä»Žä¸¤ä¸ªæ–¹é¢è€ƒè™‘
#   1.æç¤ºè¯:å¸Œæœ›å¯ä»¥æ›´æ–°æç¤ºè¯ï¼ŒæŠŠæˆ‘ä»¬çš„ä¸€äº›åŽ†å²æ¶ˆæ¯ï¼Œä¹Ÿæ”¾åˆ°æç¤ºè¯é‡Œ
#   2.æŠŠé—®é¢˜è¿›è¡Œä¸Šä¸‹æ–‡èžåˆï¼Œæ·»åŠ ä¸€ä¸ªå­é“¾ï¼Œå®ƒèƒ½å¤ŸèŽ·å–ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶ä¸”é€šè¿‡èŠå¤©åŽ†å²çš„ä¸Šä¸‹æ–‡ï¼Œæ¥é‡æ–°è¡¨è¿°è¿™ä¸ªé—®é¢˜
#       è¿™å¯ä»¥ç®€å•ç†è§£ä¸ºæž„å»ºä¸€ä¸ªæ–°çš„"åŽ†å²æ„ŸçŸ¥"æ£€æµ‹å™¨ï¼Œ
#       ä¹‹å‰æˆ‘ä»¬æœ‰ï¼šæŸ¥è¯¢->retriever
#       çŽ°åœ¨æˆ‘ä»¬æƒ³è¦ï¼šï¼ˆæŸ¥è¯¢ï¼ŒèŠå¤©åŽ†å²ï¼‰->llm->é‡æ–°è¡¨è¾¾çš„æŸ¥è¯¢->æ£€ç´¢å™¨

##é—®é¢˜ ä¸Šä¸‹æ–‡ åŒ–
# æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæç¤ºè¯ï¼Œå…¶ä¸­åŒ…å«åä¸º"chat_history"çš„MessagesPlaceholder å˜é‡ã€‚ç„¶åŽç”¨å®ƒå°†æ¶ˆæ¯åˆ—è¡¨æ’å…¥æç¤ºè¯ä¸­ï¼Œ
# è¿™äº›åŽ†å²æ¶ˆæ¯å°†ä¼šåœ¨ç³»ç»Ÿæ¶ˆæ¯ï¼ˆsystemæç¤ºè¯ï¼‰
# æˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªè¾…åŠ©å‡½æ•° create_history_aware_retrieverï¼ˆåŽ†å²æ„ŸçŸ¥æ£€ç´¢å™¨ï¼‰æ¥å¤„ç†è¿™ä¸€æ­¥ï¼Œè¿™ä¸ªå‡½æ•°ç®¡ç†chat_historyä¸ºç©ºçš„æƒ…å†µï¼Œå¦åˆ™æŒ‰é¡ºåºåº”ç”¨æç¤ºè¯|å¤§æ¨¡åž‹|è¾“å‡ºè§£æžå™¨ï¼ˆï¼‰|æ£€ç´¢å™¨
# create_history_aware_retrieveræž„å»ºä¸€ä¸ªæŽ¥å—è¾“å…¥å’ŒèŠå¤©åŽ†å²ä½œä¸ºè¾“å…¥çš„é“¾ï¼Œå¹¶å…·æœ‰ä¸Žæ£€ç´¢å™¨ç›¸åŒçš„è¾“å‡ºæ¨¡å¼
from langchain.chains import create_history_aware_retriever
from langchain_core.prompts import MessagesPlaceholder

#å…ˆæ¥å®šä¹‰ä¸€ä¸ªç³»ç»Ÿæç¤ºè¯
contextualize_q_system_prompt = (
    "ç»™å®šä¸€æ®µèŠå¤©è®°å½•ä»¥åŠæœ€æ–°çš„ç”¨æˆ·é—®é¢˜ "
    "è¯¥é—®é¢˜å¯èƒ½å¼•ç”¨äº†chat historyä¸­çš„context, "
    "å°†å…¶é‡æ–°è¡¨è¿°ä¸ºä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ï¼Œä½¿å…¶åœ¨æ²¡æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¢«ç†è§£ã€‚ "
    "ä¸è¦å›žç­”è¿™ä¸ªé—®é¢˜ï¼Œåªåœ¨å¿…è¦æ—¶å¯¹å…¶è¿›è¡Œé‡æ–°è¡¨è¿°ï¼Œå¦åˆ™åŽŸæ ·è¿”å›žã€‚"
)
#æ¥å®šä¹‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯æ¨¡æ¿ï¼Œç”±ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç³»ç»Ÿæç¤ºè¯+chat_history+input
contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", contextualize_q_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)
#åˆ›å»ºåŽ†å²æ„ŸçŸ¥æ£€ç´¢å™¨ï¼Œç”±å¤§æ¨¡åž‹ã€æ£€ç´¢å™¨å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯æž„æˆ
# å½“è°ƒç”¨äº†create_history_aware_retriever å‡½æ•°åŽï¼Œè¿”å›žçš„history_aware_retriever å¯¹è±¡å°±å†…ç½®äº†å°†è¾“å…¥æ•°æ®ä¸­çš„chat_history è‡ªåŠ¨å¡«å…¥contextualize_q_prompt å ä½ç¬¦çš„é€»è¾‘ï¼Œ
# è¿™é‡Œçš„llmæ˜¯ä¸ºäº†å’Œå·²ç»å¡«å……å¥½äº†chat_historyçš„contextualize_q_promptå°†ç”¨æˆ·çš„é—®é¢˜ç»“åˆèŠå¤©åŽ†å²ï¼ˆè¿˜æœ‰æ¨¡æ¿å•¦ï¼‰å’Œå½“å‰è¾“å…¥é‡æ–°è¡¨è¿°å‡ºä¸€ä¸ªç‹¬ç«‹é—®é¢˜
# ç„¶åŽå°†è¿™ä¸ªç‹¬ç«‹é—®é¢˜äº¤ç»™å¤–éƒ¨æ–‡æ¡£æ£€ç´¢å™¨è¿›è¡Œæ£€ç´¢
#### ç®€å•ç‚¹è¯´è¾“å…¥ä¸€æ®µæ•°æ®ï¼Œæ•°æ®ä¸­çš„èŠå¤©åŽ†å²ä¼šè¢«å¡«å…¥åˆ°contextualize_q_promptçš„chat_historyä¸­ï¼Œllmåˆ©ç”¨è¿™ä¸ªæ¨¡æ¿ç”Ÿæˆæ–°é—®é¢˜ï¼Œæ–°é—®é¢˜å°†è°ƒç”¨retrieveræŸ¥æ‰¾ç›¸å…³æ–‡æ¡£æˆ–ä¿¡æ¯ã€‚
# input->èžåˆäº†åŽ†å²è®°å½•å’Œå¤–éƒ¨æ£€ç´¢çš„newInput->llm
history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_q_prompt
)

#### è¿™æ¡é“¾å°†è¾“å…¥æŸ¥è¯¢çš„é‡è¿°ï¼ˆç»“åˆäº†åŽ†å²è®°å½•çš„ï¼‰æ·»åŠ åˆ°æˆ‘ä»¬çš„æ£€ç´¢å™¨ä¹‹å‰
# ä½†æ˜¯è¿™é‡Œçš„retrieverä¸æ˜¯æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„å¤–éƒ¨çŸ¥è¯†çš„æ£€ç´¢å™¨ä¹ˆ
# çŽ°åœ¨æˆ‘ä»¬å¯ä»¥æž„å»ºå®Œæ•´çš„é—®ç­”é“¾ï¼Œæˆ‘ä»¬è¦æŠŠä¹‹å‰çš„æ£€ç´¢å™¨æ›¿æ¢ä¸ºæˆ‘ä»¬æ–°çš„history_aware_retriever
# æˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨ä¹‹å‰çš„create_stuff_documents_chainï¼ˆåˆ›å»ºæ–‡æ¡£å¡«å……é“¾å‡½æ•°ï¼‰æ¥åˆ›å»ºä¸€ä¸ªé—®ç­”é“¾ï¼Œ
# è¾“å…¥é”®ä¸ºcontextã€chat_historyå’Œinputï¼Œå®ƒæŽ¥å—æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä»¥åŠå¯¹è¯åŽ†å²å’ŒæŸ¥è¯¢ä»¥ç”Ÿæˆç­”æ¡ˆã€‚
# ä½¿ç”¨create_retrieval_chainæž„å»ºæœ€ç»ˆçš„rag_chainï¼Œè¯¥é“¾æŒ‰é¡ºåºåº”ç”¨history_aware_retrieverï¼ˆåŽ†å²æ„ŸçŸ¥æ£€ç´¢å™¨ï¼‰å’Œquestion_answer_chainï¼ˆé—®ç­”é“¾ï¼‰
# ä¿ç•™ä¸­é—´è¾“å‡ºï¼Œä¾‹å¦‚æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä»¥ä¾¿äºŽä½¿ç”¨ï¼Œå®ƒçš„è¾“å…¥é”®ä¸ºinputå’Œchat_historyï¼Œè¾“å‡ºä¸­åŒ…æ‹¬inputã€chat_historyã€context å’Œ answer
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder("chat_history"),# èŠå¤©åŽ†å²å ä½ç¬¦ï¼šMessagesPlaceholder("chat_history") ä¼šåœ¨æ‰§è¡Œæ—¶å¡«å……ä¹‹å‰çš„å¯¹è¯è®°å½•ï¼Œä»¥ä¾¿æ¨¡åž‹äº†è§£ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        ("human", "{input}"),
    ]
)#è¿™ä¸ªæç¤ºæŠŠç”¨æˆ·è¾“å…¥ã€ç³»ç»ŸæŒ‡ä»¤ã€åŽ†å²å¯¹è¯æ”¾åœ¨ä¸€èµ·

#è¾“å…¥->qa_prompt->llm
question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
#è¾“å…¥->history_aware_retrieverèžåˆåŽ†å²æ¶ˆæ¯ä¸Žæ£€ç´¢ç”Ÿæˆæ–°é—®é¢˜->qa_prompt->llm
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

